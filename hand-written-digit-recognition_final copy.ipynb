{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa9820af18def02",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition Project\n",
    "\n",
    "## 1. Problem Description and Dataset Overview\n",
    "\n",
    "This project focuses on developing neural network models to recognize handwritten digits using the MNIST dataset, a fundamental benchmark in computer vision and machine learning. The goal is to create and compare different neural network architectures for accurate digit classification while exploring various aspects of the data and model development process.\n",
    "\n",
    "### 1.1 Dataset Description\n",
    "- **Training Set**: 60,000 handwritten digit images\n",
    "- **Test Set**: 10,000 images for independent evaluation\n",
    "- **Image Dimensions**: 28×28 pixels (grayscale)\n",
    "- **Classes**: 10 digits (0-9)\n",
    "\n",
    "### 1.2 Class Distribution Analysis\n",
    "The training data shows a relatively balanced distribution across all digits:\n",
    "- Digit 0: 5,923 samples (9.87%)\n",
    "- Digit 1: 6,742 samples (11.24%)\n",
    "- Digit 2: 5,958 samples (9.93%)\n",
    "- Digit 3: 6,131 samples (10.22%)\n",
    "- Digit 4: 5,842 samples (9.74%)\n",
    "- Digit 5: 5,421 samples (9.04%)\n",
    "- Digit 6: 5,918 samples (9.86%)\n",
    "- Digit 7: 6,265 samples (10.44%)\n",
    "- Digit 8: 5,851 samples (9.75%)\n",
    "- Digit 9: 5,949 samples (9.91%)\n",
    "\n",
    "This balanced distribution suggests that no class weighting will be necessary during model training.\n",
    "\n",
    "## 2. Data Exploration and Analysis\n",
    "\n",
    "### 2.1 Pixel Intensity Analysis\n",
    "The pixel intensity distribution analysis reveals several key characteristics:\n",
    "- Binary-like distribution with most pixels being either very dark (0) or very light (255)\n",
    "- Strong contrast between digit strokes and background\n",
    "- Clear separation between foreground and background pixels, which should facilitate feature extraction\n",
    "\n",
    "### 2.2 Feature Analysis\n",
    "Key findings from my feature analysis:\n",
    "- **Active Features**: 717 out of 784 pixels show variance across samples\n",
    "- **Constant Features**: 67 pixels (primarily in corners) remain constant\n",
    "- **Important Regions**: The heatmap visualization shows concentrated importance in the center regions where digits typically appear\n",
    "\n",
    "### 2.3 Data Quality Assessment\n",
    "- No missing values detected in either training or test sets\n",
    "- Clean, preprocessed data with consistent formatting\n",
    "- No anomalies or corruption in the pixel values\n",
    "- High-quality, standardized images suitable for training\n",
    "\n",
    "### 2.4 Data Preprocessing Strategy\n",
    "Based on my exploration, I implemented the following preprocessing steps:\n",
    "1. Normalization of pixel values to [0,1] range\n",
    "2. Reshaping data to include channel dimension (28×28×1)\n",
    "3. Creation of a validation set (10% of training data)\n",
    "4. One-hot encoding of labels\n",
    "\n",
    "Final data shapes:\n",
    "- Training set: (54000, 28, 28, 1)\n",
    "- Validation set: (6000, 28, 28, 1)\n",
    "- Test set: (10000, 28, 28, 1)\n",
    "\n",
    "This comprehensive data exploration provides a solid foundation for developing my neural network models, ensuring I understand the characteristics and quality of my input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:50:36.580362Z",
     "start_time": "2024-10-22T21:50:33.637964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import plotly.express as px\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {\n",
    "    'basic_model': {},\n",
    "    'optimized_model': {},\n",
    "    'deep_model': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bce52076a3c571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:50:37.728147Z",
     "start_time": "2024-10-22T21:50:36.580362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"Training samples: {x_train.shape[0]}\")\n",
    "print(f\"Test samples: {x_test.shape[0]}\")\n",
    "print(f\"Image dimensions: {x_train.shape[1]}x{x_train.shape[2]}\")\n",
    "\n",
    "# Print distribution\n",
    "print(\"\\nDigit Distribution in Training Set:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for digit, count in zip(unique, counts):\n",
    "    print(f\"Digit {digit}: {count}\")\n",
    "\n",
    "# Show sample images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f'Label: {y_train[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161aa4ce95f4598",
   "metadata": {},
   "source": [
    "#### Add detailed data analysis code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98054b5abbd1e701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:50:39.764287Z",
     "start_time": "2024-10-22T21:50:37.729658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pixel Intensity Analysis\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Histogram of pixel intensities\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(x_train.ravel(), bins=50)\n",
    "plt.title('Distribution of Pixel Intensities')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Average image across all samples\n",
    "plt.subplot(1, 2, 2)\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "plt.imshow(mean_image, cmap='gray')\n",
    "plt.title('Average Digit Image')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Analysis\n",
    "# Flatten images for feature analysis\n",
    "X_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "\n",
    "# Remove constant features\n",
    "feature_variance = np.var(X_flat, axis=0)\n",
    "non_constant_features = feature_variance > 0\n",
    "X_flat_filtered = X_flat[:, non_constant_features]\n",
    "\n",
    "print(f\"Original features: {X_flat.shape[1]}\")\n",
    "print(f\"Features after removing constants: {X_flat_filtered.shape[1]}\")\n",
    "\n",
    "# Select top important pixels from non-constant features\n",
    "n_features = min(196, X_flat_filtered.shape[1])\n",
    "selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "\n",
    "# Convert labels to single digits if they're one-hot encoded\n",
    "y_train_labels = np.argmax(y_train, axis=1) if len(y_train.shape) > 1 else y_train\n",
    "selector.fit(X_flat_filtered, y_train_labels)\n",
    "\n",
    "# Create importance map\n",
    "importance_map = np.zeros((28, 28))\n",
    "non_constant_indices = np.where(non_constant_features)[0]\n",
    "importance_map.ravel()[non_constant_indices] = selector.scores_\n",
    "\n",
    "# Normalize importance scores\n",
    "importance_map = np.nan_to_num(importance_map)\n",
    "importance_map = (importance_map - np.min(importance_map)) / (np.max(importance_map) - np.min(importance_map))\n",
    "\n",
    "# Visualize important pixels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(importance_map, cmap='hot')\n",
    "plt.title('Pixel Importance Heatmap')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3c371265f02a0",
   "metadata": {},
   "source": [
    "#### Code that implements data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafe96c9ce43019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:50:39.944956Z",
     "start_time": "2024-10-22T21:50:39.764287Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(x_train, x_test, y_train, y_test, validation_split=0.1):\n",
    "    \"\"\"\n",
    "    Preprocess the MNIST data for neural network training\n",
    "    \"\"\"\n",
    "    print(\"Starting data preprocessing...\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nChecking for missing values...\")\n",
    "    print(f\"Training data NaN values: {np.isnan(x_train).any()}\")\n",
    "    print(f\"Test data NaN values: {np.isnan(x_test).any()}\")\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Reshape data to include channel dimension\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    \n",
    "    # Convert class vectors to one-hot encoded labels\n",
    "    n_classes = 10\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    \n",
    "    # Split training data into training and validation sets\n",
    "    val_size = int(x_train.shape[0] * validation_split)\n",
    "    x_val = x_train[-val_size:]\n",
    "    y_val = y_train[-val_size:]\n",
    "    x_train = x_train[:-val_size]\n",
    "    y_train = y_train[:-val_size]\n",
    "    \n",
    "    print(\"\\nData shapes after preprocessing:\")\n",
    "    print(f\"Training data: {x_train.shape}\")\n",
    "    print(f\"Validation data: {x_val.shape}\")\n",
    "    print(f\"Test data: {x_test.shape}\")\n",
    "    \n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "\n",
    "# Define input shape and other parameters\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "# Preprocess the data\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = preprocess_data(x_train, \n",
    "                                                                       x_test, \n",
    "                                                                       y_train, \n",
    "                                                                       y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b1c647b1b88a2",
   "metadata": {},
   "source": [
    "#### Add code for data enhancement (this can help improve model performance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8a70f087d90e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:50:40.664042Z",
     "start_time": "2024-10-22T21:50:39.944956Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_augmentation():\n",
    "    \"\"\"\n",
    "    Create data augmentation pipeline for training\n",
    "    \"\"\"\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.1, 0.1)\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Create data augmentation pipeline\n",
    "data_augmentation = create_data_augmentation()\n",
    "\n",
    "# Visualize augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    augmented_image = data_augmentation(x_train[0:1])\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_image[0, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Augmented Image Examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c389c012324188",
   "metadata": {},
   "source": [
    "#### Add a data generator to improve training efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51cd6c2762cab90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:50:40.670563Z",
     "start_time": "2024-10-22T21:50:40.664042Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_generators(x_train, y_train, x_val, y_val, batch_size):\n",
    "    \"\"\"\n",
    "    Create data generators for training and validation\n",
    "    \"\"\"\n",
    "    # Training data generator with augmentation\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Validation data generator (no augmentation)\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "    \n",
    "    val_generator = val_datagen.flow(\n",
    "        x_val, y_val,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Create data generators\n",
    "train_generator, val_generator = create_data_generators(\n",
    "    x_train, y_train,\n",
    "    x_val, y_val,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604510d4d28f114a",
   "metadata": {},
   "source": [
    "#### Add code for experiment configuration and results tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930dc5df4402bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T21:50:40.678929Z",
     "start_time": "2024-10-22T21:50:40.670563Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration dictionary to store all hyperparameters\n",
    "config = {\n",
    "    'input_shape': input_shape,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'num_classes': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'dropout_rate': 0.25\n",
    "}\n",
    "\n",
    "# Create a dictionary to store results of different models\n",
    "if 'results' not in globals():\n",
    "    results = {\n",
    "        'basic_model': {'history': None},\n",
    "        'optimized_model': {'history': None},\n",
    "        'deep_model': {'history': None}\n",
    "    }\n",
    "\n",
    "def store_training_results(model_name, history):\n",
    "    \"\"\"\n",
    "    Store training results in the results dictionary\n",
    "    \"\"\"\n",
    "    results[model_name]['history'] = history.history\n",
    "    results[model_name]['final_accuracy'] = history.history['val_accuracy'][-1]\n",
    "    results[model_name]['best_accuracy'] = max(history.history['val_accuracy'])\n",
    "    \n",
    "print(\"Configuration and results tracking initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70c3cdf6f5942a",
   "metadata": {},
   "source": [
    "## 3. Model Development and Training\n",
    "\n",
    "### 3.1 Basic Model Development\n",
    "The basic model was implemented with a simple architecture to establish a baseline performance:\n",
    "- Input layer (784 neurons - flattened 28×28 pixels)\n",
    "- Single hidden layer (tested with 128, 256, and 512 neurons)\n",
    "- Output layer (10 neurons for digit classification)\n",
    "- ReLU activation for hidden layer, Softmax for output\n",
    "- Adam optimizer with learning rate = 0.001\n",
    "- Categorical crossentropy loss function\n",
    "\n",
    "#### Training Results:\n",
    "- 128 neurons: 98.42% validation accuracy\n",
    "- 256 neurons: 98.82% validation accuracy\n",
    "- 512 neurons: 99.00% validation accuracy\n",
    "\n",
    "The model showed consistent improvement in performance with increasing neuron count, achieving best results with 512 neurons.\n",
    "\n",
    "### 3.2 Optimized Model Development\n",
    "Based on feature importance analysis, I developed an optimized model using selected input features:\n",
    "- Reduced input dimensionality from 784 to 196 features\n",
    "- Two hidden layers (256 and 128 neurons)\n",
    "- Dropout layers (0.3 and 0.2) for regularization\n",
    "- Learning rate reduction on plateau\n",
    "- Early stopping to prevent overfitting\n",
    "\n",
    "#### Training Results:\n",
    "- Final validation accuracy: 98.05%\n",
    "- Significantly faster training (2-3ms/step vs 16-18ms/step for basic model)\n",
    "- Achieved convergence in 18 epochs\n",
    "- Reduced model complexity while maintaining high accuracy\n",
    "\n",
    "### 3.3 Deep Neural Network Development\n",
    "Implemented a more sophisticated architecture:\n",
    "- Three convolutional blocks with increasing filters (32→64→128)\n",
    "- Batch normalization after each convolution\n",
    "- MaxPooling and Dropout for regularization\n",
    "- Two dense layers (512 and 256 neurons)\n",
    "- Advanced learning rate scheduling\n",
    "\n",
    "#### Training Results:\n",
    "- Achieved highest validation accuracy: 99.68%\n",
    "- Very stable training progression\n",
    "- Excellent generalization capabilities\n",
    "- Training time: ~115ms/step\n",
    "- Reached optimal performance in 20 epochs\n",
    "\n",
    "### 3.4 Training Characteristics\n",
    "\n",
    "#### Learning Rate Adaptation:\n",
    "- All models benefited from learning rate reduction\n",
    "- Initial rate: 0.001\n",
    "- Reduction factor: 0.2\n",
    "- Minimum rate: 1e-6\n",
    "\n",
    "#### Convergence Patterns:\n",
    "1. Basic Model:\n",
    "   - Rapid initial improvement\n",
    "   - Steady convergence after epoch 10\n",
    "   - Best performance with largest (512) neuron configuration\n",
    "\n",
    "2. Optimized Model:\n",
    "   - Quick early learning\n",
    "   - More efficient training process\n",
    "   - Slight performance trade-off for efficiency\n",
    "\n",
    "3. Deep Model:\n",
    "   - Slower per-epoch training\n",
    "   - Most stable learning curve\n",
    "   - Highest final accuracy\n",
    "   - Best generalization characteristics\n",
    "\n",
    "### 3.5 Key Implementation Features\n",
    "- Data augmentation pipeline for training\n",
    "- Batch processing for memory efficiency\n",
    "- Callbacks for:\n",
    "  - Early stopping (patience=5)\n",
    "  - Learning rate reduction\n",
    "  - Model checkpointing\n",
    "- Validation split: 10% of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934f03bdf05dd19",
   "metadata": {},
   "source": [
    "#### Base Model Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d504d926c8d9515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:04:21.951949Z",
     "start_time": "2024-10-22T21:50:40.681537Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_and_train_basic_model(config, neuron_counts=[128, 256, 512]):\n",
    "    \"\"\"\n",
    "    Create and evaluate basic models with different neuron counts\n",
    "    Returns the best performing configuration\n",
    "    \"\"\"\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "    results['basic_model']['configurations'] = []\n",
    "    \n",
    "    for neurons in neuron_counts:\n",
    "        print(f\"\\nTraining basic model with {neurons} neurons...\")\n",
    "        \n",
    "        # Create model using functional API\n",
    "        inputs = keras.Input(shape=config['input_shape'])\n",
    "        x = Flatten()(inputs)\n",
    "        x = Dense(neurons, activation='relu')(x)\n",
    "        outputs = Dense(config['num_classes'], activation='softmax')(x)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=f'basic_model_{neurons}')\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=3,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=config['epochs'],\n",
    "            validation_data=val_generator,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate the model\n",
    "        val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "        \n",
    "        # Store configuration results\n",
    "        results['basic_model']['configurations'].append({\n",
    "            'neurons': neurons,\n",
    "            'val_accuracy': val_acc,\n",
    "            'history': history.history\n",
    "        })\n",
    "        \n",
    "        # Update best model if necessary\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model\n",
    "            store_training_results('basic_model', history)\n",
    "            \n",
    "        print(f\"Validation accuracy with {neurons} neurons: {val_acc:.4f}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Train different configurations of the basic model\n",
    "best_basic_model = create_and_train_basic_model(config)\n",
    "print(\"\\nBasic model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5a42e920b64e8",
   "metadata": {},
   "source": [
    "#### Optimized Model Implementation (using feature selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6468466d20ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:05:06.039707Z",
     "start_time": "2024-10-22T22:04:21.952061Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_and_train_optimized_model(config, x_train, x_val, x_test):\n",
    "    \"\"\"\n",
    "    Create optimized model using selected features based on importance\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating optimized model with selected features...\")\n",
    "    \n",
    "    try:\n",
    "        # Calculate feature importance\n",
    "        importance_map, important_pixels = calculate_feature_importance(\n",
    "            x_train, y_train, n_features=196\n",
    "        )\n",
    "        \n",
    "        # Visualize importance map\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(importance_map, cmap='hot')\n",
    "        plt.title('Feature Importance Heatmap')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create reduced datasets\n",
    "        x_train_reduced = x_train.reshape(x_train.shape[0], -1)[:, important_pixels]\n",
    "        x_val_reduced = x_val.reshape(x_val.shape[0], -1)[:, important_pixels]\n",
    "        x_test_reduced = x_test.reshape(x_test.shape[0], -1)[:, important_pixels]\n",
    "        \n",
    "        print(f\"\\nReduced feature dimensionality:\")\n",
    "        print(f\"Training data: {x_train.shape} -> {x_train_reduced.shape}\")\n",
    "        print(f\"Validation data: {x_val.shape} -> {x_val_reduced.shape}\")\n",
    "        print(f\"Test data: {x_test.shape} -> {x_test_reduced.shape}\")\n",
    "        \n",
    "        # Create model using functional API\n",
    "        inputs = keras.Input(shape=(196,))\n",
    "        x = Dense(256, activation='relu')(inputs)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        outputs = Dense(config['num_classes'], activation='softmax')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name='optimized_model')\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=3,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            x_train_reduced, y_train,\n",
    "            batch_size=config['batch_size'],\n",
    "            epochs=config['epochs'],\n",
    "            validation_data=(x_val_reduced, y_val),\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Store training results\n",
    "        store_training_results('optimized_model', history)\n",
    "        \n",
    "        # Store additional information\n",
    "        results['optimized_model'].update({\n",
    "            'selected_features': important_pixels,\n",
    "            'importance_map': importance_map,\n",
    "            'reduced_data': (x_train_reduced, x_val_reduced, x_test_reduced)\n",
    "        })\n",
    "        \n",
    "        return model, (x_train_reduced, x_val_reduced, x_test_reduced)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in create_optimized_model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def calculate_feature_importance(x_train, y_train, n_features=196):\n",
    "    \"\"\"\n",
    "    Calculate feature importance for the input data\n",
    "    \"\"\"\n",
    "    # Flatten the input data\n",
    "    X_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "    \n",
    "    # Remove constant features\n",
    "    feature_variance = np.var(X_flat, axis=0)\n",
    "    non_constant_features = feature_variance > 0\n",
    "    X_flat_filtered = X_flat[:, non_constant_features]\n",
    "    \n",
    "    print(f\"Original features: {X_flat.shape[1]}\")\n",
    "    print(f\"Non-constant features: {X_flat_filtered.shape[1]}\")\n",
    "    \n",
    "    # Select top important pixels\n",
    "    n_features = min(n_features, X_flat_filtered.shape[1])\n",
    "    selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "    \n",
    "    # For feature selection, we need the raw label indices\n",
    "    y_indices = np.argmax(y_train, axis=1) if len(y_train.shape) > 1 else y_train\n",
    "    selector.fit(X_flat_filtered, y_indices)\n",
    "    \n",
    "    # Create importance map\n",
    "    importance_map = np.zeros(X_flat.shape[1])\n",
    "    non_constant_indices = np.where(non_constant_features)[0]\n",
    "    importance_map[non_constant_indices] = selector.scores_\n",
    "    \n",
    "    # Reshape importance map to image dimensions\n",
    "    importance_map = importance_map.reshape(28, 28)\n",
    "    \n",
    "    # Get indices of top features\n",
    "    important_pixels = np.argsort(importance_map.ravel())[-n_features:]\n",
    "    \n",
    "    return importance_map, important_pixels\n",
    "\n",
    "# Create and train optimized model\n",
    "print(\"\\nStarting optimized model training...\")\n",
    "optimized_model, reduced_data = create_and_train_optimized_model(config, x_train, x_val, x_test)\n",
    "print(\"\\nOptimized model training completed.\")\n",
    "\n",
    "# Print model summary\n",
    "optimized_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898184afd58d7f8",
   "metadata": {},
   "source": [
    "#### Deep Model Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce89d8d1bd65e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:44:28.893785Z",
     "start_time": "2024-10-22T22:11:51.915350Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_and_train_deep_model(config):\n",
    "    \"\"\"\n",
    "    Create and train deep neural network model with multiple layers\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating and training deep neural network model...\")\n",
    "    \n",
    "    # Starting Model Creation with the Input Layer\n",
    "    inputs = layers.Input(shape=config['input_shape'])\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Dense Layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(config['num_classes'], activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='deep_model')\n",
    "    \n",
    "    # Compile model with gradient clipping\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=config['learning_rate'],\n",
    "            clipnorm=1.0\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=config['epochs'],\n",
    "            validation_data=val_generator,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Store training results\n",
    "        store_training_results('deep_model', history)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    # Create and train deep model\n",
    "    print(\"\\nStarting deep model training...\")\n",
    "    deep_model = create_and_train_deep_model(config)\n",
    "    print(\"\\nDeep model training completed.\")\n",
    "\n",
    "    # Print model summary\n",
    "    deep_model.summary()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in deep model creation/training: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262b1cee9da7c93",
   "metadata": {},
   "source": [
    "#### training history visualisation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76417ac380ca7a79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:46:11.591573Z",
     "start_time": "2024-10-22T22:46:10.972678Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_history(results, model_names):\n",
    "    \"\"\"\n",
    "    Plot training history for all models with error handling\n",
    "    \"\"\"\n",
    "    # Verify results exist\n",
    "    for model_name in model_names:\n",
    "        if model_name not in results:\n",
    "            print(f\"Warning: {model_name} not found in results\")\n",
    "            return\n",
    "        if 'history' not in results[model_name]:\n",
    "            print(f\"Warning: No training history found for {model_name}\")\n",
    "            return\n",
    "            \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for model_name in model_names:\n",
    "        try:\n",
    "            history = results[model_name]['history']\n",
    "            plt.plot(history['accuracy'], label=f'{model_name} (train)')\n",
    "            plt.plot(history['val_accuracy'], label=f'{model_name} (val)')\n",
    "        except KeyError as e:\n",
    "            print(f\"Error plotting {model_name}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for model_name in model_names:\n",
    "        try:\n",
    "            history = results[model_name]['history']\n",
    "            plt.plot(history['loss'], label=f'{model_name} (train)')\n",
    "            plt.plot(history['val_loss'], label=f'{model_name} (val)')\n",
    "        except KeyError as e:\n",
    "            print(f\"Error plotting {model_name}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training histories\n",
    "print(\"\\nPlotting training histories...\")\n",
    "plot_training_history(results, ['basic_model', 'optimized_model', 'deep_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed333903aee7423",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation and Performance Analysis\n",
    "\n",
    "### 4.1 Comparative Performance Analysis\n",
    "\n",
    "#### Accuracy Metrics\n",
    "1. Deep Model:\n",
    "   - Highest accuracy: 99.71%\n",
    "   - Most consistent performance across all digits\n",
    "   - Extremely low error rate: 0.29%\n",
    "   - Nearly perfect precision and recall for all classes\n",
    "\n",
    "2. Basic Model:\n",
    "   - Strong accuracy: 99.05%\n",
    "   - Very balanced performance across digits\n",
    "   - Low error rate: 0.95%\n",
    "   - Excellent macro-averaged F1-score: 0.99\n",
    "\n",
    "3. Optimized Model:\n",
    "   - Good accuracy: 97.86%\n",
    "   - Slightly lower but still robust performance\n",
    "   - Higher error rate: 2.14%\n",
    "   - Maintained F1-score of 0.98 across classes\n",
    "\n",
    "#### Computational Efficiency\n",
    "1. Model Size (Parameters):\n",
    "   - Deep Model: 1,015,530 parameters\n",
    "   - Basic Model: 407,050 parameters\n",
    "   - Optimized Model: 84,618 parameters\n",
    "\n",
    "2. Prediction Speed:\n",
    "   - Optimized Model: 0.528 seconds\n",
    "   - Basic Model: 0.621 seconds\n",
    "   - Deep Model: 4.869 seconds\n",
    "\n",
    "### 4.2 Error Analysis\n",
    "\n",
    "#### Error Patterns by Model\n",
    "\n",
    "1. Deep Model:\n",
    "   - Only 29 total errors\n",
    "   - Most confusion between visually similar digits (5/3, 7/2)\n",
    "   - Very few systematic error patterns\n",
    "   - Highest confidence in correct predictions\n",
    "\n",
    "2. Basic Model:\n",
    "   - 95 total errors\n",
    "   - Common confusions:\n",
    "     - 9→4 (7 cases)\n",
    "     - 3→5 (5 cases)\n",
    "     - 7→2 (4 cases)\n",
    "   - Generally well-distributed errors\n",
    "\n",
    "3. Optimized Model:\n",
    "   - 214 total errors\n",
    "   - Larger confusion clusters:\n",
    "     - 4→9 (23 cases)\n",
    "     - 3→5 (17 cases)\n",
    "     - 7→2 (13 cases)\n",
    "   - More systematic error patterns\n",
    "\n",
    "### 4.3 Learning Dynamics\n",
    "\n",
    "#### Training Progression\n",
    "- All models showed rapid initial learning\n",
    "- Deep model achieved high accuracy earliest\n",
    "- Optimized model showed more fluctuation\n",
    "- Basic model demonstrated steady improvement\n",
    "\n",
    "#### Validation Performance\n",
    "- Deep model maintained consistent validation accuracy\n",
    "- Basic model showed minimal overfitting\n",
    "- Optimized model had slightly higher variance\n",
    "\n",
    "### 4.4 Model-Specific Strengths\n",
    "\n",
    "1. Deep Model:\n",
    "   - Best overall accuracy\n",
    "   - Most robust to input variations\n",
    "   - Excellent feature extraction\n",
    "   - Highest confidence predictions\n",
    "\n",
    "2. Basic Model:\n",
    "   - Good balance of accuracy and speed\n",
    "   - Consistent performance\n",
    "   - Reasonable resource requirements\n",
    "   - Stable training behavior\n",
    "\n",
    "3. Optimized Model:\n",
    "   - Most efficient resource usage\n",
    "   - Fastest prediction time\n",
    "   - Smallest model size\n",
    "   - Acceptable accuracy trade-off\n",
    "\n",
    "### 4.5 Trade-off Analysis\n",
    "\n",
    "#### Accuracy vs. Resources\n",
    "- Deep Model: Highest accuracy but requires significant computational resources\n",
    "- Basic Model: Good balance of accuracy and resource usage\n",
    "- Optimized Model: Most efficient but with some accuracy compromise\n",
    "\n",
    "#### Speed vs. Accuracy\n",
    "- Clear inverse relationship between prediction speed and accuracy\n",
    "- Optimized model offers best speed-to-accuracy ratio\n",
    "- Deep model demonstrates the accuracy ceiling with speed penalty\n",
    "\n",
    "#### Model Size vs. Performance\n",
    "- Smaller models (Optimized) show competitive performance\n",
    "- Larger models (Deep) provide incremental accuracy improvements\n",
    "- Resource requirements scale non-linearly with performance gains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19869c6d522e049d",
   "metadata": {},
   "source": [
    "#### Comprehensive Evaluation Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b343590af280d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:46:24.524838Z",
     "start_time": "2024-10-22T22:46:17.592762Z"
    }
   },
   "outputs": [],
   "source": [
    "def comprehensive_evaluation(model, x_test, y_test, model_name, config):\n",
    "    \"\"\"\n",
    "    Perform comprehensive evaluation of a model\n",
    "    \"\"\"\n",
    "    print(f\"\\nComprehensive Evaluation for {model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Timing prediction speed\n",
    "        start_time = time.time()\n",
    "        y_pred = model.predict(x_test)\n",
    "        prediction_time = time.time() - start_time\n",
    "        \n",
    "        # Convert predictions to class labels\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true_classes = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "        report = classification_report(y_true_classes, y_pred_classes)\n",
    "        conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name]['evaluation'] = {\n",
    "            'accuracy': accuracy,\n",
    "            'prediction_time': prediction_time,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'classification_report': report,\n",
    "            'predictions': y_pred,\n",
    "            'true_labels': y_test,\n",
    "            'model_size': model.count_params()\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nModel Performance Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Prediction Time: {prediction_time:.4f} seconds\")\n",
    "        print(f\"Model Size: {model.count_params():,} parameters\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.show()\n",
    "        \n",
    "        return results[model_name]['evaluation']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluation: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Evaluate all models\n",
    "for model_name, model in [\n",
    "    ('basic_model', best_basic_model),\n",
    "    ('optimized_model', optimized_model),\n",
    "    ('deep_model', deep_model)\n",
    "]:\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    if model_name == 'optimized_model':\n",
    "        # Use reduced test data for optimized model\n",
    "        x_test_eval = results['optimized_model']['reduced_data'][2]\n",
    "    else:\n",
    "        x_test_eval = x_test\n",
    "        \n",
    "    comprehensive_evaluation(model, x_test_eval, y_test, model_name, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28dd39c2afd3fd",
   "metadata": {},
   "source": [
    "#### Visualisation of model comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6768a63349559c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:46:28.802019Z",
     "start_time": "2024-10-22T22:46:28.478598Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_model_comparison(results):\n",
    "    \"\"\"\n",
    "    Create visualizations comparing the performance of different models\n",
    "    \"\"\"\n",
    "    model_names = ['basic_model', 'optimized_model', 'deep_model']\n",
    "    \n",
    "    # Performance metrics\n",
    "    metrics = {\n",
    "        'Accuracy': [results[m]['evaluation']['accuracy'] for m in model_names],\n",
    "        'Prediction Time': [results[m]['evaluation']['prediction_time'] for m in model_names],\n",
    "        'Model Size': [results[m]['evaluation']['model_size'] for m in model_names]\n",
    "    }\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Accuracy Comparison\n",
    "    plt.subplot(131)\n",
    "    plt.bar(model_names, metrics['Accuracy'])\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 2: Prediction Time Comparison\n",
    "    plt.subplot(132)\n",
    "    plt.bar(model_names, metrics['Prediction Time'])\n",
    "    plt.title('Prediction Time Comparison')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 3: Model Size Comparison\n",
    "    plt.subplot(133)\n",
    "    plt.bar(model_names, metrics['Model Size'])\n",
    "    plt.title('Model Size Comparison')\n",
    "    plt.ylabel('Number of Parameters')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Model': model_names,\n",
    "        'Accuracy': metrics['Accuracy'],\n",
    "        'Prediction Time (s)': metrics['Prediction Time'],\n",
    "        'Model Size': metrics['Model Size']\n",
    "    })\n",
    "    \n",
    "    print(\"\\nModel Comparison Summary:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "# Visualize model comparisons\n",
    "print(\"\\nGenerating model comparison visualizations...\")\n",
    "visualize_model_comparison(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbfd528ad196219",
   "metadata": {},
   "source": [
    "#### Adds error analysis functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7b7ae17df535a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:51:07.186034Z",
     "start_time": "2024-10-22T22:50:57.597990Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_errors(model, x_test, y_test, model_name, is_optimized=False):\n",
    "    \"\"\"\n",
    "    Analyze and visualize model prediction errors\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        x_test: Test data\n",
    "        y_test: Test label\n",
    "        model_name: Model name\n",
    "        is_optimized: Is it an optimised model (using downscaled data)\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalyzing prediction errors for {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Get predictions\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true_classes = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        # Find misclassified examples\n",
    "        errors = (y_pred_classes != y_true_classes)\n",
    "        x_errors = x_test[errors]\n",
    "        y_pred_errors = y_pred_classes[errors]\n",
    "        y_true_errors = y_true_classes[errors]\n",
    "        \n",
    "        # Calculate error statistics\n",
    "        error_rate = np.mean(errors)\n",
    "        error_count = np.sum(errors)\n",
    "        \n",
    "        print(f\"\\nError Analysis Statistics:\")\n",
    "        print(f\"Total errors: {error_count}\")\n",
    "        print(f\"Error rate: {error_rate:.4f}\")\n",
    "        \n",
    "        # Plot some misclassified examples\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.suptitle(f'Misclassified Examples by {model_name}')\n",
    "        \n",
    "        for i in range(min(10, len(x_errors))):\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            if is_optimized:\n",
    "                # For optimized model, we'll just show the feature values as a line plot\n",
    "                plt.plot(x_errors[i])\n",
    "                plt.title(f'True: {y_true_errors[i]}\\nPred: {y_pred_errors[i]}')\n",
    "            else:\n",
    "                if len(x_errors[i].shape) == 3:\n",
    "                    plt.imshow(x_errors[i][:,:,0], cmap='gray')\n",
    "                else:\n",
    "                    plt.imshow(x_errors[i].reshape(28, 28), cmap='gray')\n",
    "                plt.title(f'True: {y_true_errors[i]}\\nPred: {y_pred_errors[i]}')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyze error patterns\n",
    "        error_matrix = confusion_matrix(y_true_errors, y_pred_errors)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(error_matrix, annot=True, fmt='d', cmap='Reds')\n",
    "        plt.title(f'Error Pattern Analysis for {model_name}')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'error_rate': error_rate,\n",
    "            'error_count': error_count,\n",
    "            'error_matrix': error_matrix\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in error analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Store original test data for visualization\n",
    "original_x_test = x_test.copy()\n",
    "\n",
    "# Analyze errors for each model\n",
    "for model_name, model in [\n",
    "    ('basic_model', best_basic_model),\n",
    "    ('optimized_model', optimized_model),\n",
    "    ('deep_model', deep_model)\n",
    "]:\n",
    "    print(f\"\\nAnalyzing errors for {model_name}...\")\n",
    "    \n",
    "    # Determine if it is an optimised model\n",
    "    is_optimized = model_name == 'optimized_model'\n",
    "    \n",
    "    if is_optimized:\n",
    "        # Using the reduced test data\n",
    "        x_test_eval = results['optimized_model']['reduced_data'][2]\n",
    "    else:\n",
    "        # Using raw test data\n",
    "        x_test_eval = original_x_test\n",
    "    \n",
    "    results[model_name]['error_analysis'] = analyze_errors(\n",
    "        model, x_test_eval, y_test, model_name, is_optimized\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909b59f6ebd146a",
   "metadata": {},
   "source": [
    "## 5. Sensitivity Analysis and Model Robustness\n",
    "\n",
    "### 5.1 Feature Importance Analysis\n",
    "\n",
    "#### Deep Model\n",
    "- Center regions show highest gradient-based importance\n",
    "- Clear concentration of important features in digit stroke areas\n",
    "- Hierarchical feature importance pattern from center outward\n",
    "- Very low noise sensitivity (mean: 0.0008)\n",
    "\n",
    "#### Basic Model\n",
    "- More dispersed feature importance pattern\n",
    "- Moderate sensitivity to input perturbations\n",
    "- Good robustness to noise (dropout rate: 0.4037)\n",
    "- Consistent feature utilization across image\n",
    "\n",
    "#### Optimized Model\n",
    "- Highly selective feature utilization\n",
    "- Strong peaks in feature importance for key pixel locations\n",
    "- Higher sensitivity to perturbations (mean: 0.2259)\n",
    "- More efficient but less robust feature processing\n",
    "\n",
    "### 5.2 Perturbation Analysis Results\n",
    "\n",
    "#### Noise Tolerance\n",
    "1. Deep Model:\n",
    "   - Maintains >90% accuracy up to 0.2 noise level\n",
    "   - Graceful degradation with increasing noise\n",
    "   - Best overall robustness (0.6620)\n",
    "\n",
    "2. Basic Model:\n",
    "   - Sharp accuracy drop after 0.2 noise level\n",
    "   - Moderate robustness (0.4037)\n",
    "   - Linear degradation pattern\n",
    "\n",
    "3. Optimized Model:\n",
    "   - Most sensitive to noise\n",
    "   - Rapid performance deterioration\n",
    "   - Lowest robustness score (0.2259)\n",
    "\n",
    "#### Occlusion Sensitivity\n",
    "- All models show highest sensitivity in central regions\n",
    "- Deep model maintains performance with partial occlusion\n",
    "- Basic model shows moderate occlusion tolerance\n",
    "- Optimized model most affected by occlusion\n",
    "\n",
    "## 6. Final Conclusions and Recommendations\n",
    "\n",
    "### 6.1 Model Selection Guidelines\n",
    "\n",
    "#### For Maximum Accuracy (>99.5%)\n",
    "- Use Deep Model\n",
    "- Benefits:\n",
    "  - 99.71% accuracy\n",
    "  - Excellent robustness\n",
    "  - Best feature extraction\n",
    "- Considerations:\n",
    "  - Higher computational cost\n",
    "  - Longer prediction time (4.87s)\n",
    "  - Larger model size (1,015,530 parameters)\n",
    "\n",
    "#### For Resource-Constrained Environments\n",
    "- Use Optimized Model\n",
    "- Benefits:\n",
    "  - Fastest prediction (0.53s)\n",
    "  - Smallest size (84,618 parameters)\n",
    "  - Good accuracy (97.86%)\n",
    "- Considerations:\n",
    "  - Lower noise tolerance\n",
    "  - Higher error rate\n",
    "  - Limited feature extraction\n",
    "\n",
    "#### For Balanced Performance\n",
    "- Use Basic Model\n",
    "- Benefits:\n",
    "  - Good accuracy (99.05%)\n",
    "  - Moderate resource usage\n",
    "  - Reasonable speed (0.62s)\n",
    "- Considerations:\n",
    "  - Middle-ground solution\n",
    "  - Good robustness\n",
    "  - Balanced trade-offs\n",
    "\n",
    "### 6.2 Implementation Insights\n",
    "\n",
    "1. Feature Engineering:\n",
    "   - Central image regions most important\n",
    "   - Edge pixels less critical\n",
    "   - Noise filtering crucial for stability\n",
    "\n",
    "2. Training Considerations:\n",
    "   - Early stopping effective for all models\n",
    "   - Learning rate adaptation important\n",
    "   - Data augmentation beneficial\n",
    "\n",
    "3. Deployment Recommendations:\n",
    "   - Consider hardware constraints\n",
    "   - Monitor inference time requirements\n",
    "   - Balance accuracy vs. resource usage\n",
    "\n",
    "### 6.3 Future Improvements\n",
    "\n",
    "1. Model Enhancements:\n",
    "   - Explore hybrid architectures\n",
    "   - Optimize feature selection\n",
    "   - Investigate quantization options\n",
    "\n",
    "2. Performance Optimization:\n",
    "   - Fine-tune hyperparameters\n",
    "   - Implement model pruning\n",
    "   - Explore model compression\n",
    "\n",
    "3. Robustness Improvements:\n",
    "   - Enhanced data augmentation\n",
    "   - Adversarial training\n",
    "   - Ensemble methods\n",
    "\n",
    "### 6.4 Final Assessment\n",
    "\n",
    "The project successfully developed and compared three distinct approaches to handwritten digit recognition, each offering unique advantages:\n",
    "\n",
    "1. Deep Model: Achieved state-of-the-art accuracy with robust feature extraction\n",
    "2. Optimized Model: Demonstrated efficient resource utilization\n",
    "3. Basic Model: Provided balanced performance characteristics\n",
    "\n",
    "The comprehensive analysis shows that all models are viable solutions, with selection depending on specific deployment requirements and constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af284a88b66f869",
   "metadata": {},
   "source": [
    "#### Sensitivity Analysis Realisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977f9e6028028bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:56:55.736468Z",
     "start_time": "2024-10-22T22:55:38.760427Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_occlusion_analysis(model, x_samples, y_samples, patch_size=3, is_optimized=False):\n",
    "    \"\"\"\n",
    "    Perform occlusion sensitivity analysis\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        x_samples: Input Sample\n",
    "        y_samples: Label Sample\n",
    "        patch_size: Size of the occlusion patch\n",
    "        is_optimized: Is it an optimized model (using downscaled data)\n",
    "    \"\"\"\n",
    "    if is_optimized:\n",
    "        # For optimised models, use feature masking analysis\n",
    "        n_features = x_samples.shape[1]\n",
    "        sensitivity_map = np.zeros(n_features)\n",
    "        \n",
    "        # Masking one set of features at a time\n",
    "        patch_size = min(10, n_features // 10)  # Resize patch\n",
    "        for i in range(0, n_features, patch_size):\n",
    "            end_idx = min(i + patch_size, n_features)\n",
    "            \n",
    "            # Creating Masking Samples\n",
    "            occluded = x_samples.copy()\n",
    "            occluded[:, i:end_idx] = 0\n",
    "            \n",
    "            # Change in measurement accuracy\n",
    "            original_pred = model.predict(x_samples)\n",
    "            occluded_pred = model.predict(occluded)\n",
    "            \n",
    "            # Calculation of sensitivity\n",
    "            sensitivity = np.mean(np.abs(original_pred - occluded_pred))\n",
    "            sensitivity_map[i:end_idx] = sensitivity\n",
    "            \n",
    "        return sensitivity_map.reshape(-1, 1)  # Returns a 2D array for uniform processing\n",
    "    \n",
    "    else:\n",
    "        # For CNN models, image occlusion analysis is used\n",
    "        sensitivity_map = np.zeros((28, 28))\n",
    "        \n",
    "        for i in range(0, 28 - patch_size + 1, 2):\n",
    "            for j in range(0, 28 - patch_size + 1, 2):\n",
    "                # Creating Masking Samples\n",
    "                occluded = x_samples.copy()\n",
    "                occluded[:, i:i+patch_size, j:j+patch_size, :] = 0\n",
    "                \n",
    "                # Change in measurement accuracy\n",
    "                original_pred = model.predict(x_samples)\n",
    "                occluded_pred = model.predict(occluded)\n",
    "                \n",
    "                # Calculation of sensitivity\n",
    "                sensitivity = np.mean(np.abs(original_pred - occluded_pred))\n",
    "                sensitivity_map[i:i+patch_size, j:j+patch_size] = sensitivity\n",
    "        \n",
    "        return sensitivity_map\n",
    "\n",
    "def perform_sensitivity_analysis(model, x_test, y_test, model_name, config):\n",
    "    \"\"\"\n",
    "    Comprehensive sensitivity analysis for the model\n",
    "    \"\"\"\n",
    "    print(f\"\\nPerforming Sensitivity Analysis for {model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Check if it is an optimized model\n",
    "        is_optimized = model_name == 'optimized_model'\n",
    "        \n",
    "        results[model_name]['sensitivity'] = {}\n",
    "        \n",
    "        # 1. Gradient-based Feature Importance\n",
    "        print(\"Calculating gradient-based importance...\")\n",
    "        gradients = calculate_gradient_importance(model, x_test[:1000])\n",
    "        \n",
    "        # 2. Perturbation Analysis\n",
    "        print(\"Performing perturbation analysis...\")\n",
    "        perturbation_scores = perform_perturbation_analysis(\n",
    "            model, x_test[:1000], y_test[:1000]\n",
    "        )\n",
    "        \n",
    "        # 3. Occlusion Sensitivity\n",
    "        print(\"Calculating occlusion sensitivity...\")\n",
    "        occlusion_map = perform_occlusion_analysis(\n",
    "            model, x_test[:100], y_test[:100],\n",
    "            is_optimized=is_optimized\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name]['sensitivity'].update({\n",
    "            'gradient_importance': gradients,\n",
    "            'perturbation_scores': perturbation_scores,\n",
    "            'occlusion_map': occlusion_map\n",
    "        })\n",
    "        \n",
    "        # Visualize results\n",
    "        visualize_sensitivity_results(model_name, results[model_name]['sensitivity'])\n",
    "        \n",
    "        # Generate and print summary report\n",
    "        sensitivity_report = generate_sensitivity_report(\n",
    "            model_name, \n",
    "            results[model_name]['sensitivity']\n",
    "        )\n",
    "        \n",
    "        return sensitivity_report\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in sensitivity analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def visualize_sensitivity_results(model_name, sensitivity_results):\n",
    "    \"\"\"\n",
    "    Visualize sensitivity analysis results\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 1. Gradient Importance\n",
    "    plt.subplot(131)\n",
    "    if model_name == 'optimized_model':\n",
    "        plt.plot(sensitivity_results['gradient_importance'])\n",
    "        plt.title('Feature Importance')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Importance')\n",
    "    else:\n",
    "        plt.imshow(sensitivity_results['gradient_importance'], cmap='hot')\n",
    "        plt.title('Gradient-based Importance')\n",
    "        plt.colorbar()\n",
    "    \n",
    "    # 2. Perturbation Analysis\n",
    "    plt.subplot(132)\n",
    "    pert_results = sensitivity_results['perturbation_scores']\n",
    "    noise_levels = [r['noise_level'] for r in pert_results]\n",
    "    accuracies = [r['accuracy'] for r in pert_results]\n",
    "    plt.plot(noise_levels, accuracies)\n",
    "    plt.title('Perturbation Sensitivity')\n",
    "    plt.xlabel('Noise Level')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    # 3. Occlusion Sensitivity\n",
    "    plt.subplot(133)\n",
    "    if model_name == 'optimized_model':\n",
    "        plt.plot(sensitivity_results['occlusion_map'])\n",
    "        plt.title('Feature Sensitivity')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Sensitivity')\n",
    "    else:\n",
    "        plt.imshow(sensitivity_results['occlusion_map'], cmap='hot')\n",
    "        plt.title('Occlusion Sensitivity')\n",
    "        plt.colorbar()\n",
    "    \n",
    "    plt.suptitle(f'Sensitivity Analysis for {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform sensitivity analysis for each model\n",
    "print(\"\\nStarting sensitivity analysis for all models...\")\n",
    "for model_name, model in [\n",
    "    ('basic_model', best_basic_model),\n",
    "    ('optimized_model', optimized_model),\n",
    "    ('deep_model', deep_model)\n",
    "]:\n",
    "    print(f\"\\nAnalyzing sensitivity for {model_name}...\")\n",
    "    if model_name == 'optimized_model':\n",
    "        x_test_eval = results['optimized_model']['reduced_data'][2]\n",
    "    else:\n",
    "        x_test_eval = x_test\n",
    "        \n",
    "    results[model_name]['sensitivity_report'] = perform_sensitivity_analysis(\n",
    "        model, x_test_eval, y_test, model_name, config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4c1f103156ea4",
   "metadata": {},
   "source": [
    "#### Final summary and report generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c02bb13a3f651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:57:15.107370Z",
     "start_time": "2024-10-22T22:57:15.093212Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_final_report(results, config):\n",
    "    \"\"\"\n",
    "    Generate final comprehensive report of all models and their performance\n",
    "    \"\"\"\n",
    "    print(\"\\nFinal Report: MNIST Handwritten Digit Recognition\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Model Architecture Summary\n",
    "    print(\"\\n1. Model Architectures:\")\n",
    "    for model_name in ['basic_model', 'optimized_model', 'deep_model']:\n",
    "        print(f\"\\n{model_name.upper()}:\")\n",
    "        print(\"-\" * 40)\n",
    "        if model_name in results:\n",
    "            print(f\"Parameters: {results[model_name]['evaluation']['model_size']:,}\")\n",
    "            print(f\"Accuracy: {results[model_name]['evaluation']['accuracy']:.4f}\")\n",
    "            print(f\"Prediction Time: {results[model_name]['evaluation']['prediction_time']:.4f} seconds\")\n",
    "    \n",
    "    # 2. Performance Comparison\n",
    "    print(\"\\n2. Performance Comparison:\")\n",
    "    print(\"-\" * 40)\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Model': ['Basic', 'Optimized', 'Deep'],\n",
    "        'Accuracy': [results[m]['evaluation']['accuracy'] for m in ['basic_model', 'optimized_model', 'deep_model']],\n",
    "        'Prediction Time': [results[m]['evaluation']['prediction_time'] for m in ['basic_model', 'optimized_model', 'deep_model']],\n",
    "        'Model Size': [results[m]['evaluation']['model_size'] for m in ['basic_model', 'optimized_model', 'deep_model']]\n",
    "    })\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # 3. Key Findings\n",
    "    print(\"\\n3. Key Findings:\")\n",
    "    print(\"-\" * 40)\n",
    "    best_model = max(\n",
    "        ['basic_model', 'optimized_model', 'deep_model'],\n",
    "        key=lambda x: results[x]['evaluation']['accuracy']\n",
    "    )\n",
    "    print(f\"Best performing model: {best_model}\")\n",
    "    print(f\"Best accuracy achieved: {results[best_model]['evaluation']['accuracy']:.4f}\")\n",
    "    \n",
    "    # 4. Sensitivity Analysis Summary\n",
    "    print(\"\\n4. Sensitivity Analysis Summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    for model_name in ['basic_model', 'optimized_model', 'deep_model']:\n",
    "        print(f\"\\n{model_name.upper()}:\")\n",
    "        report = results[model_name]['sensitivity_report']\n",
    "        print(f\"Gradient Importance Mean: {report['gradient_importance_stats']['mean']:.4f}\")\n",
    "        print(f\"Perturbation Robustness: {report['perturbation_robustness']['accuracy_drop_rate']:.4f}\")\n",
    "        print(f\"Occlusion Sensitivity Mean: {report['occlusion_sensitivity']['mean']:.4f}\")\n",
    "    \n",
    "    # 5. Recommendations\n",
    "    print(\"\\n5. Recommendations:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Based on the analysis, we recommend:\")\n",
    "    if results['deep_model']['evaluation']['accuracy'] > 0.99:\n",
    "        print(\"- Using the deep model for highest accuracy\")\n",
    "    if results['optimized_model']['evaluation']['prediction_time'] == min(\n",
    "        results[m]['evaluation']['prediction_time'] for m in ['basic_model', 'optimized_model', 'deep_model']\n",
    "    ):\n",
    "        print(\"- Using the optimized model for fastest prediction time\")\n",
    "    print(\"- Consider model size vs. performance tradeoffs based on deployment constraints\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Generate final report\n",
    "final_comparison = generate_final_report(results, config)\n",
    "\n",
    "# Save results if needed\n",
    "# np.save('mnist_results.npy', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0aa83c080ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
